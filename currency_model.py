# -*- coding: utf-8 -*-
"""currency model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-4Mi_nroSgDdX88FCli_fAa_2t2jE96
"""

# !pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="868TaqkwHhPtIstulvnK")
project = rf.workspace("iit-pallakkad").project("detect-indian-currency")
version = project.version(2)
dataset = version.download("tensorflow")

# !pip install tensorflow keras scikit-learn opencv-python matplotlib seaborn

import os

data_dir = dataset.location
print(f"Contents of {data_dir}:")
print(os.listdir(data_dir))

import os

train_annotations_path = os.path.join(data_dir, 'train', '_annotations.csv')
test_annotations_path = os.path.join(data_dir, 'test', '_annotations.csv')
valid_annotations_path = os.path.join(data_dir, 'valid', '_annotations.csv')

print(f"Train annotations path: {train_annotations_path}")
print(f"Test annotations path: {test_annotations_path}")
print(f"Valid annotations path: {valid_annotations_path}")

import pandas as pd

train_df = pd.read_csv(train_annotations_path)
test_df = pd.read_csv(test_annotations_path)
valid_df = pd.read_csv(valid_annotations_path)

import os

train_df['image_path'] = train_df['filename'].apply(lambda x: os.path.join(data_dir, 'train', x))

print("Updated train_df with 'image_path' column:")
train_df.head()

import os

test_df['image_path'] = test_df['filename'].apply(lambda x: os.path.join(data_dir, 'test', x))

print("Updated test_df with 'image_path' column:")
test_df.head()

import os

valid_df['image_path'] = valid_df['filename'].apply(lambda x: os.path.join(data_dir, 'valid', x))

print("Updated valid_df with 'image_path' column:")
valid_df.head()

import cv2

def load_and_preprocess_image(image_path, target_size, bboxes):
    img = cv2.imread(image_path)

    if img is None:
        print(f"Error: Could not load image from {image_path}")
        return None, None

    original_height, original_width, _ = img.shape

    if bboxes:
        xmin, ymin, xmax, ymax = bboxes[0]


        xmin = max(0, xmin)
        ymin = max(0, ymin)
        xmax = min(original_width, xmax)
        ymax = min(original_height, ymax)


        cropped_img = img[ymin:ymax, xmin:xmax]

        if cropped_img.shape[0] == 0 or cropped_img.shape[1] == 0:
            print(f"Warning: Cropping resulted in an empty image for {image_path}. Skipping.")
            return None, None


        original_cropped_width = cropped_img.shape[1]
        original_cropped_height = cropped_img.shape[0]
        img_to_resize = cropped_img

    else:
        original_cropped_width = original_width
        original_cropped_height = original_height
        img_to_resize = img


    resized_img = cv2.resize(img_to_resize, target_size, interpolation=cv2.INTER_LINEAR)


    scale_width = target_size[0] / original_cropped_width
    scale_height = target_size[1] / original_cropped_height


    scaled_bboxes = []

    for bbox in bboxes:
        adj_xmin = bbox[0] - xmin if bboxes else bbox[0]
        adj_ymin = bbox[1] - ymin if bboxes else bbox[1]
        adj_xmax = bbox[2] - xmin if bboxes else bbox[2]
        adj_ymax = bbox[3] - ymin if bboxes else bbox[3]

        scaled_xmin = int(adj_xmin * scale_width)
        scaled_ymin = int(adj_ymin * scale_height)
        scaled_xmax = int(adj_xmax * scale_width)
        scaled_ymax = int(adj_ymax * scale_height)
        scaled_bboxes.append([scaled_xmin, scaled_ymin, scaled_xmax, scaled_ymax])

    return resized_img, scaled_bboxes

print("Defined load_and_preprocess")

"""## Example for doing the above function by using one image ferrom train"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2
example_row = train_df.iloc[0]
image_path = example_row['image_path']
original_width = example_row['width']
original_height = example_row['height']

example_filename = example_row['filename']
bboxes_for_example_image = train_df[train_df['filename'] == example_filename][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()
print(f"Example image path: {image_path}")
print(f"Example bounding boxes: {bboxes_for_example_image}")

target_size = (640, 640)

preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, bboxes_for_example_image)

plt.figure(figsize=(12, 6))

if preprocessed_img is not None:
    print(f"Original image dimensions: {original_width}x{original_height}")
    print(f"Preprocessed image shape: {preprocessed_img.shape}")
    print(f"Original Bounding Boxes: {bboxes_for_example_image}")
    print(f"Scaled Bounding Boxes: {scaled_bboxes}")


    original_img = cv2.imread(image_path)
    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)


    for bbox in bboxes_for_example_image:
        xmin, ymin, xmax, ymax = bbox
        cv2.rectangle(original_img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2) # Red rectangle


    preprocessed_img_rgb = cv2.cvtColor(preprocessed_img, cv2.COLOR_BGR2RGB)


    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.imshow(original_img)
    plt.title(f'Original Image with BBoxes ({original_img.shape[1]}x{original_img.shape[0]})')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(preprocessed_img_rgb)
    plt.title(f'Cropped and Resized Image ({preprocessed_img_rgb.shape[1]}x{preprocessed_img_rgb.shape[0]})')
    plt.axis('off')

    # plt.show()
else:
    print("Failed to preprocess image.")

"""##Preprocess and prepare datasets for valid traon test by using above function"""

train_images = []
train_bboxes = []
error_images = []

unique_train_images = train_df['filename'].unique()
target_size = (512, 512)

print(f"Preprocessing {len(unique_train_images)} training images...")

for filename in unique_train_images:
    image_path = os.path.join(data_dir, 'train', filename)
    bboxes_for_image = train_df[train_df['filename'] == filename][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()

    preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, bboxes_for_image)

    if preprocessed_img is not None:
        train_images.append(preprocessed_img)
        train_bboxes.append(scaled_bboxes)
    else:
        error_images.append(image_path)

print("Training data preprocessing complete.")
print(f"Number of preprocessed training images: {len(train_images)}")
print(f"Number of corresponding bounding box sets: {len(train_bboxes)}")
print(f"Number of images with preprocessing errors: {len(error_images)}")

import random
import matplotlib.pyplot as plt
import cv2


unique_filenames_train = train_df['filename'].unique()


random_filename = random.choice(unique_filenames_train)


random_image_path = os.path.join(data_dir, 'train', random_filename)


bboxes_for_random_image = train_df[train_df['filename'] == random_filename][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()

print(f"Selected random image: {random_filename}")
print(f"Original bounding boxes: {bboxes_for_random_image}")

target_size_for_display = (640, 640)

preprocessed_img, _ = load_and_preprocess_image(random_image_path, target_size_for_display, bboxes_for_random_image)

if preprocessed_img is not None:

    original_img = cv2.imread(random_image_path)
    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)

    for bbox in bboxes_for_random_image:
        xmin, ymin, xmax, ymax = bbox
        cv2.rectangle(original_img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)


    preprocessed_img_rgb = cv2.cvtColor(preprocessed_img, cv2.COLOR_BGR2RGB)


    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.imshow(original_img)
    plt.title(f'Original Image with bounding bbcaad')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(preprocessed_img_rgb)
    plt.title(f'Cropped and Resized Image')
    plt.axis('off')

    # plt.show()
else:
    print("Failed to load or preprocess the selected image.")

test_images = []
test_bboxes = []
error_test_images = []

unique_test_images = test_df['filename'].unique()
target_size = (512, 512)

print(f"Preprocessing {len(unique_test_images)} test images...")

for filename in unique_test_images:
    image_path = os.path.join(data_dir, 'test', filename)
    bboxes_for_image = test_df[test_df['filename'] == filename][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()

    preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, bboxes_for_image)

    if preprocessed_img is not None:
        test_images.append(preprocessed_img)
        test_bboxes.append(scaled_bboxes)
    else:
        error_test_images.append(image_path)

print("Test data preprocessing complete.")
print(f"Number of preprocessed test images: {len(test_images)}")
print(f"Number of corresponding bounding box sets: {len(test_bboxes)}")
print(f"Number of images with preprocessing errors: {len(error_test_images)}")

valid_images = []
valid_bboxes = []
error_valid_images = []

unique_valid_images = valid_df['filename'].unique()
target_size = (512, 512)

print(f"Preprocessing {len(unique_valid_images)} validation images...")

for filename in unique_valid_images:
    image_path = os.path.join(data_dir, 'valid', filename)
    bboxes_for_image = valid_df[valid_df['filename'] == filename][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()

    preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, bboxes_for_image)

    if preprocessed_img is not None:
        valid_images.append(preprocessed_img)
        valid_bboxes.append(scaled_bboxes)
    else:
        error_valid_images.append(image_path)

print("Validation data preprocessing complete.")
print(f"Number of preprocessed validation images: {len(valid_images)}")
print(f"Number of corresponding bounding box sets: {len(valid_bboxes)}")
print(f"Number of images with preprocessing errors: {len(error_valid_images)}")

import numpy as np
print(f"Number of preprocessed training images: {len(train_images)}")
print(f"Number of preprocessed test images: {len(test_images)}")
print(f"Number of preprocessed validation images: {len(valid_images)}")


print(f"Number of training bounding box sets: {len(train_bboxes)}")
print(f"Number of test bounding box sets: {len(test_bboxes)}")
print(f"Number of validation bounding box sets: {len(valid_bboxes)}")
print("Removed explicit numpy array conversions to prevent memory issues.")

all_classes = pd.concat([train_df['class'], test_df['class'], valid_df['class']]).unique()
class_to_id = {cls_name: i for i, cls_name in enumerate(all_classes)}
id_to_class = {i: cls_name for cls_name, i in class_to_id.items()}

print("Class to ID mapping:")
print(class_to_id)
print(f"Total unique classes: {len(all_classes)}")

"""## Make generator as memory outage to avoid.
### Seperate data generator for trainig a epoch with avoidign repeating dataset for trai test val
"""

import numpy as np

def train_data_generator(data_dir, class_to_id, target_size=(512, 512), batch_size=32):

    unique_filenames = train_df['filename'].unique()
    num_images = len(unique_filenames)
    subset_dir = 'train'

    i = 0
    while True:
        batch_images = []
        batch_labels = []

        for _ in range(batch_size):
            if i >= num_images:
                i = 0
                np.random.shuffle(unique_filenames)

            filename = unique_filenames[i]
            image_path = os.path.join(data_dir, subset_dir, filename)

            image_annotations = train_df[train_df['filename'] == filename]
            original_bboxes = image_annotations[['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()
            original_classes = image_annotations['class'].values.tolist()

            preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, original_bboxes)

            if preprocessed_img is not None and original_classes:
                single_label_id = class_to_id[original_classes[0]]
                batch_images.append(preprocessed_img)
                batch_labels.append(single_label_id)

            i += 1

        if batch_images:
            yield np.array(batch_images, dtype=np.float32), np.array(batch_labels, dtype=np.int32)

def test_data_generator(data_dir, class_to_id, target_size=(512, 512), batch_size=32):
    unique_filenames = test_df['filename'].unique()
    num_images = len(unique_filenames)
    subset_dir = 'test'

    i = 0
    while True:
        batch_images = []
        batch_labels = []

        for _ in range(batch_size):
            if i >= num_images:
                i = 0
                np.random.shuffle(unique_filenames)

            filename = unique_filenames[i]
            image_path = os.path.join(data_dir, subset_dir, filename)

            image_annotations = test_df[test_df['filename'] == filename]
            original_bboxes = image_annotations[['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()
            original_classes = image_annotations['class'].values.tolist()

            preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, original_bboxes)

            if preprocessed_img is not None and original_classes:
                single_label_id = class_to_id[original_classes[0]]
                batch_images.append(preprocessed_img)
                batch_labels.append(single_label_id)

            i += 1

        if batch_images:
            yield np.array(batch_images, dtype=np.float32), np.array(batch_labels, dtype=np.int32)

def valid_data_generator(data_dir, class_to_id, target_size=(512, 512), batch_size=32):

    unique_filenames = valid_df['filename'].unique()
    num_images = len(unique_filenames)
    subset_dir = 'valid'

    i = 0
    while True:
        batch_images = []
        batch_labels = []

        for _ in range(batch_size):
            if i >= num_images:
                i = 0
                np.random.shuffle(unique_filenames)

            filename = unique_filenames[i]
            image_path = os.path.join(data_dir, subset_dir, filename)

            image_annotations = valid_df[valid_df['filename'] == filename]
            original_bboxes = image_annotations[['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()
            original_classes = image_annotations['class'].values.tolist()

            preprocessed_img, scaled_bboxes = load_and_preprocess_image(image_path, target_size, original_bboxes)

            if preprocessed_img is not None and original_classes:
                single_label_id = class_to_id[original_classes[0]]
                batch_images.append(preprocessed_img)
                batch_labels.append(single_label_id)

            i += 1

        if batch_images:
            yield np.array(batch_images, dtype=np.float32), np.array(batch_labels, dtype=np.int32)

valid_generator = valid_data_generator(data_dir, class_to_id, target_size=(640, 640), batch_size=4)
test_generator = test_data_generator(data_dir, class_to_id, target_size=(640, 640), batch_size=4)

train_generator = train_data_generator(data_dir, class_to_id, target_size=(640, 640), batch_size=4)

images, labels = next(train_generator)

print(f"Shape of images in batch: {images.shape}")

print(f"Number of labels sets in batch: {len(labels)}")
print(f"Example labels for the first image in batch:\n{labels[3]}")

"""# 1.Basic CNN model architecture and training.

- from research and analysis.
-
"""


import tensorflow as tf
from tensorflow.keras import layers, models

# Configure GPU memory growth
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"Verified: {len(gpus)} GPU(s) available. Memory growth enabled.")
    except RuntimeError as e:
        print(e)



num_classes = len(class_to_id)
input_shape = (target_size[0], target_size[1], 3)


model = models.Sequential([

    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),


    layers.Flatten(),


    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])


model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

model.summary()

batch_size = 8
steps_per_epoch_train = len(train_df['filename'].unique()) // batch_size
steps_per_epoch_valid = len(valid_df['filename'].unique()) // batch_size


train_generator = train_data_generator(data_dir, class_to_id, target_size=target_size, batch_size=batch_size)
valid_generator = valid_data_generator(data_dir, class_to_id, target_size=target_size, batch_size=batch_size)


print("Starting model traininggg")
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch_train,
    epochs=50,
    validation_data=valid_generator,
    validation_steps=steps_per_epoch_valid
)

print("\nModel training finished.")